# Copyright 2021 Open Ag Data Alliance
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

x-release:
  environment:
    # Default to loading packaged default config?
    &env
    CONFIG: ${OADA_CONFIG-/oada.config.mjs}
    NODE_ENV: ${NODE_ENV-production}
    DEBUG: ${DEBUG-*}
    INSPECT: ${INSPECT-}
    PINO_LEVEL: ${PINO_LEVEL-info}
    DEBUG_HIDE_DATE: ~
    DEBUG_COLORS: ~
    DEBUG_DEPTH: ~
    DEBUG_SHOW_HIDDEN: ~
    PINO_TRANSPORT: ~
    DOMAIN: ~
    NODE_TLS_REJECT_UNAUTHORIZED: ~
    # Allow changing arangodb URL (e.g., to use external arango)
    ARANGODB_URL: ${ARANGODB_URL-http://arangodb:8529}
    # Allow changing kafka brokers (e.g., to use external kafka)
    KAFKA_BROKERS: ${KAFKA_BROKERS-kafka:9092}

services:
  startup:
    environment:
      <<: *env
      # set RESETDATABASE to "yes" if you want to drop database on startup
      # and recreate it
      RESETDATABASE: ${RESETDATABASE-no}

  auth:
    environment:
      <<: *env

  http-handler:
    environment:
      <<: *env
      IGNORE_SCOPE:
    volumes:
      # Storage for non-JSON resources
      - binary_data:/oada/binary

  sync-handler:
    environment:
      <<: *env
      IGNORE_SCOPE:


  write-handler:
    environment:
      <<: *env

  users:
    environment:
      <<: *env

  rev-graph-update:
    environment:
      <<: *env

  well-known:
    environment:
      <<: *env

  webhooks:
    environment:
      <<: *env

  shares:
    environment:
      <<: *env

  # swag with configs for auth, well-known, and http-handler
  #
  # Handles reverse proxying to services and SSL certs.
  #
  # Can be replaced with any other reverse proxy solution.
  # Needs to route:
  #   /oadaauth -> auth
  #   /.well-known -> well-known
  #   / -> http-handler websockets
  #   all other OADA requestes -> http-handler
  proxy:
    #volumes:
    #  To disable fetching SSL certs (e.g. to serve localhost)
    #  Generate your own fullchain.pem and privkey.pem
    #  put them into /config/keys/letsencrypt (see below)
    #  - /path/to/certs:/config/keys/letsencrypt:ro
    environment:
      PUID: 1000
      PGID: 1000
      TZ: America/New_york
      URL: ${DOMAIN}
      SUBDOMAINS: #e.g., www
      VALIDATION: http
      CERTPROVIDER: #optional
      DNSPLUGIN: #optional
      PROPAGATION: #optional
      DUCKDNSTOKEN: #optional
      EMAIL: #optional
      ONLY_SUBDOMAINS: 'false' #optional
      EXTRA_DOMAINS: #optional
      STAGING: 'false' #optional
      MAXMINDDB_LICENSE_KEY: #optional
    volumes:
      - proxy_config:/config
    ports:
      - '${BIND:-0.0.0.0}:${PORT_HTTPS:-443}:443'
      - '${BIND:-0.0.0.0}:${PORT_HTTP:-80}:80'

  # Arango is the main backend where core data and graph are stored
  #
  # You could use an external arango instance instead.
  # The services just need hostname `arango` to resolve to arango instance(s)
  arangodb:
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - arangodb_apps_data:/var/lib/arangodb3-apps
    environment:
      # ARANGO_RANDOM_ROOT_PASSWORD: 1
      ARANGO_NO_AUTH: 1
      ARANGO_STORAGE_ENGINE: rocksdb

  # You could use an external kafka instance instead.
  # The services just need hostname `kafka`
  # to resolve to redpanda/kafka instance(s)
  redpanda:
    environment:
      REDPANDA_MODE: ${REDPANDA_MODE-production}
    volumes:
      #- /var/run/docker.sock:/var/run/docker.sock
      - redpanda_data:/var/lib/redpanda/data
      - redpanda_config:/etc/redpanda/

  prometheus:
    volumes:
      - prometheus_data:/prometheus
      - prometheus_config:/etc/prometheus

  rpk-prometheus-conf:
    volumes:
      - prometheus_config:/etc/prometheus

  grafana:
    volumes:
      - grafana_data:/var/lib/grafana
      - grafana_prov:/etc/grafana/provisioning

  grafana-provision-dashboards:
    volumes:
      - grafana_prov:/etc/grafana/provisioning

  grafana-provision-prometheus:
    volumes:
      - grafana_prov:/etc/grafana/provisioning

  rpk-grafana-dashboard:
    volumes:
      - grafana_data:/var/lib/grafana
      - grafana_prov:/etc/grafana/provisioning

volumes:
  arangodb_data:
  arangodb_apps_data:
  binary_data:
  redpanda_data:
  redpanda_config:
  proxy_config:
  prometheus_data:
  prometheus_config:
  grafana_data:
  grafana_prov:


x-mutagen:
  # Set up Mutagen forwards
  # Only take effect if using `mutagen compose` rather than `docker-compose`
  # see https://mutagen.io/documentation/orchestration/compose
  forward:
    agrango:
      source: 'tcp:localhost:8529'
      destination: 'network://arango_net:tcp:arangodb:8529'
    kafka:
      source: 'tcp:localhost:9092'
      destination: 'network://kafka_net:tcp:kafka:9092'
    prometheus:
      source: 'tcp:localhost:9090'
      destination: 'network://grafana_net:tcp:prometheus:9090'
    grafana:
      source: 'tcp:localhost:3000'
      destination: 'network://grafana_net:tcp:grafana:3000'
