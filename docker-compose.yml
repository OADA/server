services:
  startup:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/startup:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: startup
    depends_on:
      - redpanda
      - arangodb
    expose:
      # expose only internally, not on host
      - '8080'
    environment:
      # set RESETDATABASE to "yes" if you want to drop database on startup and recreate
      RESETDATABASE: ${RESETDATABASE-no}

  auth:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/auth:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: auth
    depends_on:
      - startup
    networks:
      http_net: {}
    expose:
      # expose only internally, not on host
      - '8080'

  # http-handler is in charge of maintaining connectiongs to clients and starting
  # the first message for a request into Kafka
  http-handler:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/http-handler:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: http-handler
    healthcheck:
      test: ['CMD', 'yarn', 'healthcheck']
    depends_on:
      - startup
    networks:
      http_net: {}
    expose:
      # expose only internally, not on host
      - '8080'
    ports:
      # Expose node inspect port
      - 9230:9229
    environment:
      IGNORE_SCOPE:
    volumes:
      # Storage for non-JSON resources
      - binary_data:/oada/binary

  sync-handler:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/sync-handler:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: sync-handler
    depends_on:
      - startup
      - proxy
    networks:
      http_net: {}
    environment:
      IGNORE_SCOPE:

  write-handler:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/write-handler:${OADA_VERSION-build}
    ports:
      # Expose node inspect port
      - 9231:9229
    build:
      args:
        OADA_SERVICE: write-handler
    depends_on:
      - startup

  users:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/users:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: users
    depends_on:
      - startup

  rev-graph-update:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/rev-graph-update:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: rev-graph-update
    depends_on:
      - startup

  well-known:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/well-known:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: well-known
    depends_on:
      - startup
    networks:
      http_net: {}
    expose:
      # expose only internally, not on host
      - '8080'

  webhooks:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/webhooks:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: webhooks
    depends_on:
      - startup
      - proxy
    networks:
      http_net: {}

  shares:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/shares:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: shares
    depends_on:
      - startup

  # swag with configs for auth, well-known, and http-handler
  proxy:
    build: ./support/proxy
    image: oada/support-proxy:${OADA_VERSION-build}
    cap_add:
      - NET_ADMIN
    networks:
      http_net: {}
    environment:
      PUID: 1000
      PGID: 1000
      TZ: America/New_york
      URL: ${DOMAIN:-localhost}
      SUBDOMAINS: #e.g., www
      VALIDATION: http
      CERTPROVIDER: #optional
      DNSPLUGIN: #optional
      PROPAGATION: #optional
      DUCKDNSTOKEN: #optional
      EMAIL: #optional
      ONLY_SUBDOMAINS: 'false' #optional
      EXTRA_DOMAINS: #optional
      STAGING: 'true' #optional (set false for release)
      MAXMINDDB_LICENSE_KEY: #optional
    volumes:
      - proxy_config:/config
      # Hack in self-signed ssl for localhost
      - ./support/proxy/selfsigned:/config/keys/letsencrypt:ro
    ports:
      - '${BIND:-0.0.0.0}:${PORT_HTTPS:-443}:443'
      - '${BIND:-0.0.0.0}:${PORT_HTTP:-80}:80'
    restart: unless-stopped

  # Arango is the main backend where core data and graph is stored
  arangodb:
    image: arangodb:3.9.1
    restart: unless-stopped
    networks:
      arango_net: {}
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - arangodb_apps_data:/var/lib/arangodb3-apps
    expose:
      # expose only internally, not on host
      - '8529'
    environment:
      # - ARANGO_RANDOM_ROOT_PASSWORD=1
      ARANGO_NO_AUTH: 1
      ARANGO_STORAGE_ENGINE: rocksdb
    command: ['arangod', '--server.statistics=false']

  # Redpanda is API compatible with kafka.
  redpanda:
    image: vectorized/redpanda:v21.4.13
    restart: unless-stopped
    networks:
      kafka_net:
        aliases:
          - kafka
    volumes:
      - redpanda_data:/var/lib/redpanda/data
      - redpanda_config:/etc/redpanda/
    environment:
      REDPANDA_MODE: ${REDPANDA_MODE-development}
    entrypoint:
      - /bin/sh
      - -c
      # Configure then run redpanda?
      # TODO: Better way to set this?
      - |
        rpk redpanda mode $$REDPANDA_MODE &&
        rpk $$@
      - rpk
    command:
      - redpanda
      - start
      - --smp
      - '1'
      - --reserve-memory
      - 0M
      - --overprovisioned
      - --kafka-addr
      - PLAINTEXT://kafka:9092
      - --rpc-addr
      - 0.0.0.0:33145
      - --node-id
      - '0'
      - --advertise-kafka-addr
      - PLAINTEXT://kafka:9092
    expose:
      # Kafka API port
      - '9092'
      # Internal RPC port
      - '33145'
      # Prometheus/HTTP Admin port
      - '9644'

  pino-pretty:
    deploy:
      replicas: 0
    image: oada/startup:${OADA_VERSION-build}
    restart: never
    command: g:pino-pretty -C /.pino-prettyrc
    volumes:
      - ./.pino-prettyrc:/.pino-prettyrc

  prometheus:
    image: prom/prometheus
    profiles:
      - dashboard
      - debug
    depends_on:
      - rpk-prometheus-conf
      - redpanda
    restart: unless-stopped
    networks:
      grafana_net: {}
      kafka_net: {}
    expose:
      - '9090'
    #ports:
    #  - '9090:9090'
    volumes:
      - prometheus_data:/prometheus
      - prometheus_config:/etc/prometheus

  # Generate redpanda config for prometheus
  # TODO: Better way to do this?
  rpk-prometheus-conf:
    extends:
      service: redpanda
    profiles:
      - dashboard
      - debug
    restart: on-failure
    volumes:
      - prometheus_config:/etc/prometheus
    user: root
    entrypoint:
      - '/bin/sh'
      - -c
    command:
      - |
        echo -n "scrape_configs:" > /etc/prometheus/prometheus.yml &&
        rpk generate --seed-addr=redpanda prometheus-config >> /etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana
    profiles:
      - dashboard
      - debug
    depends_on:
      - prometheus
      - grafana-provision-prometheus
      - grafana-provision-dashboards
    restart: unless-stopped
    networks:
      grafana_net:
    ports:
      - '3000:3000'
    volumes:
      - grafana_data:/var/lib/grafana
      - grafana_prov:/etc/grafana/provisioning

  # Provision a grafana dashboard provider.
  #
  # Loads all dashboards in /var/lib/grafana/dashboards
  #
  # TODO: Better way to do this?
  grafana-provision-dashboards:
    image: grafana/grafana
    profiles:
      - dashboard
      - debug
    depends_on:
      - rpk-grafana-dashboard
    restart: on-failure
    volumes:
      - grafana_prov:/etc/grafana/provisioning
    entrypoint:
      - '/bin/sh'
      - -c
    command:
      - |
        echo '
        apiVersion: 1
        providers:
          - name: "dashboard provider"
            type: file
            options:
              path: /var/lib/grafana/dashboards
              foldersFromFileStructure: true
        ' > /etc/grafana/provisioning/dashboards/dashboards.yml

  # Provision our prometheus instance as a grafana datasource
  # TODO: Better way to do this?
  grafana-provision-prometheus:
    image: grafana/grafana
    profiles:
      - dashboard
      - debug
    restart: on-failure
    volumes:
      - grafana_prov:/etc/grafana/provisioning
    entrypoint:
      - '/bin/sh'
      - -c
    command:
      - |
        echo '
        apiVersion: 1
        deleteDatasources:
          - name: Prometheus
        datasources:
          - name: Prometheus
            type: prometheus
            access: proxy
            url: http://prometheus:9090
        ' > /etc/grafana/provisioning/datasources/prometheus.yml

  # Generate dashboard for our redpanda with our prometheus instance
  # TODO: Better way to do this?
  rpk-grafana-dashboard:
    extends:
      service: redpanda
    profiles:
      - dashboard
      - debug
    restart: on-failure
    volumes:
      - grafana_data:/var/lib/grafana
      - grafana_prov:/etc/grafana/provisioning
    entrypoint:
      - '/bin/sh'
      - -c
    command:
      - |
        mkdir -p /var/lib/grafana/dashboards/
        rpk generate grafana-dashboard \
          --datasource Prometheus \
          --prometheus-url redpanda:9644/metrics \
          > /var/lib/grafana/dashboards/redpanda.json

volumes:
  arangodb_data:
  arangodb_apps_data:
  binary_data:
  redpanda_data:
  redpanda_config:
  proxy_config:
  prometheus_data:
  prometheus_config:
  grafana_data:
  grafana_prov:

networks:
  arango_net: {}
  kafka_net: {}
  http_net: {}
  startup_net: {}
  grafana_net: {}

# Set up Mutagen forwards
x-mutagen:
  forward:
    agrango:
      source: 'tcp:localhost:8529'
      destination: 'network://arango_net:tcp:arangodb:8529'
    kafka:
      source: 'tcp:localhost:9092'
      destination: 'network://kafka_net:tcp:kafka:9092'
    prometheus:
      source: 'tcp:localhost:9090'
      destination: 'network://grafana_net:tcp:prometheus:9090'
    grafana:
      source: 'tcp:localhost:3000'
      destination: 'network://grafana_net:tcp:grafana:3000'
